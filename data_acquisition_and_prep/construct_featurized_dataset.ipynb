{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Featurized Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listdir_nohidden(path):\n",
    "    return glob.glob(os.path.join(path, '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_moving_averages(df, window_sizes=[1,2,3,4,5,6,7,8], alphas = [.01, .05, .1, .2, .3, .5, .75, .9, .95]):\n",
    "    \n",
    "    #Create a copy of original df to apply moving average transformations to\n",
    "    #And shift all rows down by 1 (don't want to predict current game's outcome with current game's stats)\n",
    "    df_copy = df.copy().loc[:, ~df.columns.isin(['id','date','season','home','opp', 'w/l'])].shift()\n",
    "    \n",
    "    #Create df to append all transformed columns to one df\n",
    "    moving_average_df = df[['id', 'pt_diff', 'date', 'season', 'home']].copy()\n",
    "    \n",
    "    df_list = [moving_average_df]\n",
    "    \n",
    "    for w in window_sizes:\n",
    "        #Apply (equally weighted) rolling average to df\n",
    "        temp_df = df_copy.rolling(window=w, min_periods=1).mean()\n",
    "        \n",
    "        #Add suffix to all columns designating which operation was applied\n",
    "        temp_df = temp_df.add_suffix(\"_roll_{}\".format(w))\n",
    "        \n",
    "        df_list.append(temp_df)\n",
    "        \n",
    "    for a in alphas:\n",
    "        temp_df = df_copy.ewm(alpha=a).mean()\n",
    "        temp_df = temp_df.add_suffix(\"_exp_{}\".format(a))\n",
    "        \n",
    "        df_list.append(temp_df)\n",
    "        \n",
    "    #Combine all moving average dfs into one\n",
    "    df_merged = pd.concat(df_list,axis=1)\n",
    "    \n",
    "    df_merged.insert(1, 'games_played', df_merged.index + 1)\n",
    "    \n",
    "    return df_merged\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def days_since_last_game(df):\n",
    "    \n",
    "    #Get the number of days since last game each game in season\n",
    "    dates = pd.to_datetime(df['date'])\n",
    "    \n",
    "    return (dates - dates.shift()).dt.days.fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consec_away_games(df):\n",
    "    \n",
    "    #Get # of consecutive away games for each game in season\n",
    "    \n",
    "    num_consec = 0\n",
    "    consec_list = []\n",
    "    for home in df['home']:\n",
    "        if home == 0:\n",
    "            num_consec += 1\n",
    "            consec_list.append(num_consec)\n",
    "        else:\n",
    "            num_consec = 0\n",
    "            consec_list.append(num_consec)\n",
    "            \n",
    "    return consec_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013\n",
      "2014\n",
      "2015\n",
      "2012\n",
      "1994\n",
      "1995\n",
      "2008\n",
      "2001\n",
      "2006\n",
      "2007\n",
      "2000\n",
      "2009\n",
      "2017\n",
      "2010\n",
      "2019\n",
      "2020\n",
      "2018\n",
      "2011\n",
      "2016\n",
      "1997\n",
      "1999\n",
      "1998\n",
      "1996\n",
      "2005\n",
      "2002\n",
      "2003\n",
      "2004\n"
     ]
    }
   ],
   "source": [
    "#apply feature extraction methods to each individual gamelog and save resulting df\n",
    "\n",
    "working_dir = '/Users/gregyannett/Documents/nba_game_models/data/'\n",
    "\n",
    "for year_dir in listdir_nohidden(working_dir+'gamelogs'):\n",
    "    \n",
    "    year = year_dir[-4:]\n",
    "    \n",
    "    os.mkdir(working_dir+'featurized_gamelogs/{year}'.format(year=year))\n",
    "    \n",
    "    for gamelog_path in listdir_nohidden(year_dir):\n",
    "        \n",
    "        gamelog = pd.read_csv(gamelog_path)\n",
    "        \n",
    "        #Extract features from data\n",
    "        feature_df = apply_moving_averages(gamelog)\n",
    "        feature_df['days_since_last'] = days_since_last_game(feature_df)\n",
    "        feature_df['back2back'] = np.where(feature_df['days_since_last']==1, 1, 0)\n",
    "        feature_df['consec_away'] = consec_away_games(feature_df)\n",
    "        \n",
    "        #save data to featurized_gamelogs directory\n",
    "        fpath = working_dir + '/featurized_gamelogs/{year}/{team}_{year}.csv'.format(team=gamelog_path[-12:-9], year=year)\n",
    "        feature_df.to_csv(fpath, index=False)\n",
    "        \n",
    "    print(year)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = '/Users/gregyannett/Documents/nba_game_models/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013\n",
      "2014\n",
      "2015\n",
      "2012\n",
      "1994\n",
      "1995\n",
      "2008\n",
      "2001\n",
      "2006\n",
      "2007\n",
      "2000\n",
      "2009\n",
      "2017\n",
      "2010\n",
      "2019\n",
      "2021\n",
      "2020\n",
      "2018\n",
      "2011\n",
      "2016\n",
      "1997\n",
      "1999\n",
      "1998\n",
      "1996\n",
      "2005\n",
      "2002\n",
      "2003\n",
      "2004\n"
     ]
    }
   ],
   "source": [
    "#Gets comprehensive dataframe of all games from all seasons (moving average stats, schedule features, etc for both home and away teams)\n",
    "\n",
    "working_dir = '/Users/gregyannett/Documents/nba_game_models/data/'\n",
    "\n",
    "home_dfs = []\n",
    "away_dfs = []\n",
    "\n",
    "for year_dir in listdir_nohidden(working_dir + 'featurized_gamelogs'):\n",
    "    \n",
    "    year = year_dir[-4:]\n",
    "    \n",
    "    for gamelog_path in listdir_nohidden(year_dir):\n",
    "        \n",
    "        temp = pd.read_csv(gamelog_path)\n",
    "        \n",
    "        is_home = temp['home'].values.astype(bool)\n",
    "        \n",
    "        temp = temp.drop(['home'], axis=1)\n",
    "        \n",
    "        home = temp[is_home]\n",
    "        \n",
    "        home_dfs.append(home)\n",
    "        \n",
    "        away = temp[~is_home]\n",
    "        away = away.drop(['date'],axis=1)\n",
    "        \n",
    "        away.columns = ['{}{}'.format('' if c == 'id' else 'away_', c) for c in away.columns]\n",
    "        \n",
    "        away_dfs.append(away)  \n",
    "        \n",
    "    print(year)\n",
    "    \n",
    "all_home_games = pd.concat(home_dfs)\n",
    "all_away_games = pd.concat(away_dfs)\n",
    "\n",
    "all_games = all_home_games.merge(all_away_games, on='id').reset_index(drop=True)\n",
    "\n",
    "all_games.to_csv(working_dir + 'datasets/all_games.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
