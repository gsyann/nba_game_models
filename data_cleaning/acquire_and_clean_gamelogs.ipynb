{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Gamelogs from Basketball Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_gamelogs(team, year):\n",
    "    \"\"\"\n",
    "    Scrapes and joins the regular and advanced game logs for a given team and year from basketball reference\n",
    "    \n",
    "    team - 3 letter team abbreviation \n",
    "    year - season to scrape data from\n",
    "    \n",
    "    Returns scraped gamelog as a DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    #format url\n",
    "    base_url = \"https://www.basketball-reference.com/teams/\" \n",
    "    url = base_url + team + '/' + str(year) + '/gamelog'\n",
    "    \n",
    "    #scrape regular gamelog\n",
    "    df = pd.read_html(url, header = 1)[0]\n",
    "    \n",
    "    #scrape advanced gamelog\n",
    "    url += '-advanced'\n",
    "    df_advanced = pd.read_html(url, header = 1)[0]\n",
    "    \n",
    "    #drop duplicate columns before joining gamelogs\n",
    "    duplicate_cols = list(set(df.columns) & set(df_advanced.columns))\n",
    "    df_advanced = df_advanced.drop(duplicate_cols, axis=1)\n",
    "\n",
    "    #join regular and advanced gamelogs\n",
    "    df = df.join(df_advanced)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_id(df, team):\n",
    "    \"\"\"\n",
    "    Creates unique ids for each game played in the format of \n",
    "        yyyy-mm-dd_XXX_YYY\n",
    "        \n",
    "        where XXX is home team abbrev, YYY is away team abbrev\n",
    "    \"\"\"\n",
    "    team = team.upper()\n",
    "    ids = np.where(df['home'] == 1, (df['date']+\"_\"+team+\"_\"+df['opp']).str.upper(), (df['date']+\"_\"+df['opp']+\"_\"+team).str.upper())\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_gamelog(df, team, year):\n",
    "    \"\"\"\n",
    "    Clean and format the gamelog df\n",
    "    \n",
    "    df - gamelog DataFrame\n",
    "    \n",
    "    Returns cleaned gamelog df\n",
    "    \"\"\"\n",
    "    \n",
    "    #lowercase all columns\n",
    "    df.columns = [x.lower() for x in df.columns]\n",
    "    \n",
    "    #rename columns\n",
    "    df = df.rename({'tm':'pts', 'opp.1':'opp_pts'}, axis = 1)\n",
    "    \n",
    "    #create flag for home/away game; home = 1\n",
    "    df.insert(4, 'home', np.where(df['unnamed: 3'] == '@', 0, 1))\n",
    "    \n",
    "    # Add unique id for each game\n",
    "    df.insert(0, 'id', make_id(df, team))\n",
    "    \n",
    "    #replace win/loss column with 1/0 flag; 1 = win\n",
    "    df['w/l'] = np.where(df['w/l']=='W',1,0)\n",
    "    \n",
    "    #drop opponent/unnecessary/empty columns\n",
    "    cols_to_drop = ['rk', 'g'] + [x for x in df.columns if 'unnamed' in x or '.1' in x]\n",
    "    df = df.drop(cols_to_drop, axis=1)\n",
    "    \n",
    "    #drop the empty rows that bbref use to break up their tables\n",
    "    divider_rows = [20,21,42,43,64,65,86,87]\n",
    "\n",
    "    #ignore errors to accomodate shortened seasons\n",
    "    df = df.drop(divider_rows, errors='ignore')\n",
    "    \n",
    "    #convert applicable columns to int/float\n",
    "    for col in list(df.columns):\n",
    "        df[col] = df[col].apply(lambda x: pd.to_numeric(x, errors='ignore'))\n",
    "    \n",
    "    #create column for game's point differential\n",
    "    df['pt_diff'] = df['pts'] - df['opp_pts']\n",
    "    \n",
    "    df.insert(2, 'season', year)\n",
    "    \n",
    "    #reset index\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gamelog(team, year):\n",
    "    \"\"\"\n",
    "    Calls functions to scrape, combine, and clean normal and advanced (regular season) gamelogs for a given team and year\n",
    "    \n",
    "    team - 3 letter team abbreviation \n",
    "    year - season to scrape data from\n",
    "    \n",
    "    Returns cleaned gamelog as a DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    #call gamelog scraper\n",
    "    gamelog = scrape_gamelogs(team, year)\n",
    "    \n",
    "    #call cleaner function\n",
    "    gamelog = clean_gamelog(gamelog, team, year)\n",
    "\n",
    "    return gamelog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_abbreviations = {\n",
    " 2021: ['ATL','BOS','BRK','CHI','CHO','CLE','DAL','DEN','DET','GSW','HOU','IND','LAC','LAL','MEM','MIA','MIL','MIN','NOP','NYK','OKC','ORL','PHI','PHO','POR','SAC','SAS','TOR','UTA','WAS'],\n",
    " 2020: ['ATL','BOS','BRK','CHI','CHO','CLE','DAL','DEN','DET','GSW','HOU','IND','LAC','LAL','MEM','MIA','MIL','MIN','NOP','NYK','OKC','ORL','PHI','PHO','POR','SAC','SAS','TOR','UTA','WAS'],\n",
    " 2019: ['ATL','BOS','BRK','CHI','CHO','CLE','DAL','DEN','DET','GSW','HOU','IND','LAC','LAL','MEM','MIA','MIL','MIN','NOP','NYK','OKC','ORL','PHI','PHO','POR','SAC','SAS','TOR','UTA','WAS'],\n",
    " 2018: ['ATL','BOS','BRK','CHI','CHO','CLE','DAL','DEN','DET','GSW','HOU','IND','LAC','LAL','MEM','MIA','MIL','MIN','NOP','NYK','OKC','ORL','PHI','PHO','POR','SAC','SAS','TOR','UTA','WAS'],\n",
    " 2017: ['ATL','BOS','BRK','CHI','CHO','CLE','DAL','DEN','DET','GSW','HOU','IND','LAC','LAL','MEM','MIA','MIL','MIN','NOP','NYK','OKC','ORL','PHI','PHO','POR','SAC','SAS','TOR','UTA','WAS'],\n",
    " 2016: ['ATL','BOS','BRK','CHI','CHO','CLE','DAL','DEN','DET','GSW','HOU','IND','LAC','LAL','MEM','MIA','MIL','MIN','NOP','NYK','OKC','ORL','PHI','PHO','POR','SAC','SAS','TOR','UTA','WAS'],\n",
    " 2015: ['ATL','BOS','BRK','CHI','CHO','CLE','DAL','DEN','DET','GSW','HOU','IND','LAC','LAL','MEM','MIA','MIL','MIN','NOP','NYK','OKC','ORL','PHI','PHO','POR','SAC','SAS','TOR','UTA','WAS'],\n",
    " 2014: ['ATL','BOS','BRK','CHA','CHI','CLE','DAL','DEN','DET','GSW','HOU','IND','LAC','LAL','MEM','MIA','MIL','MIN','NOP','NYK','OKC','ORL','PHI','PHO','POR','SAC','SAS','TOR','UTA','WAS'],\n",
    " 2013: ['ATL','BOS','BRK','CHA','CHI','CLE','DAL','DEN','DET','GSW','HOU','IND','LAC','LAL','MEM','MIA','MIL','MIN','NOH','NYK','OKC','ORL','PHI','PHO','POR','SAC','SAS','TOR','UTA','WAS'],\n",
    " 2012: ['ATL','BOS','CHA','CHI','CLE','DAL','DEN','DET','GSW','HOU','IND','LAC','LAL','MEM','MIA','MIL','MIN','NJN','NOH','NYK','OKC','ORL','PHI','PHO','POR','SAC','SAS','TOR','UTA','WAS'],\n",
    " 2011: ['ATL','BOS','CHA','CHI','CLE','DAL','DEN','DET','GSW','HOU','IND','LAC','LAL','MEM','MIA','MIL','MIN','NJN','NOH','NYK','OKC','ORL','PHI','PHO','POR','SAC','SAS','TOR','UTA','WAS'],\n",
    " 2010: ['ATL','BOS','CHA','CHI','CLE','DAL','DEN','DET','GSW','HOU','IND','LAC','LAL','MEM','MIA','MIL','MIN','NJN','NOH','NYK','OKC','ORL','PHI','PHO','POR','SAC','SAS','TOR','UTA','WAS'],\n",
    " 2009: ['ATL','BOS','CHA','CHI','CLE','DAL','DEN','DET','GSW','HOU','IND','LAC','LAL','MEM','MIA','MIL','MIN','NJN','NOH','NYK','OKC','ORL','PHI','PHO','POR','SAC','SAS','TOR','UTA','WAS'],\n",
    " 2008: ['ATL','BOS','CHA','CHI','CLE','DAL','DEN','DET','GSW','HOU','IND','LAC','LAL','MEM','MIA','MIL','MIN','NJN','NOH','NYK','ORL','PHI','PHO','POR','SAC','SAS','SEA','TOR','UTA','WAS'],\n",
    " 2007: ['ATL','BOS','CHA','CHI','CLE','DAL','DEN','DET','GSW','HOU','IND','LAC','LAL','MEM','MIA','MIL','MIN','NJN','NOK','NYK','ORL','PHI','PHO','POR','SAC','SAS','SEA','TOR','UTA','WAS'],\n",
    " 2006: ['ATL','BOS','CHA','CHI','CLE','DAL','DEN','DET','GSW','HOU','IND','LAC','LAL','MEM','MIA','MIL','MIN','NJN','NOK','NYK','ORL','PHI','PHO','POR','SAC','SAS','SEA','TOR','UTA','WAS'],\n",
    " 2005: ['ATL','BOS','CHA','CHI','CLE','DAL','DEN','DET','GSW','HOU','IND','LAC','LAL','MEM','MIA','MIL','MIN','NJN','NOH','NYK','ORL','PHI','PHO','POR','SAC','SAS','SEA','TOR','UTA','WAS'],\n",
    " 2004: ['ATL','BOS','CHI','CLE','DAL','DEN','DET','GSW','HOU','IND','LAC','LAL','MEM','MIA','MIL','MIN','NJN','NOH','NYK','ORL','PHI','PHO','POR','SAC','SAS','SEA','TOR','UTA','WAS'],\n",
    " 2003: ['ATL','BOS','CHI','CLE','DAL','DEN','DET','GSW','HOU','IND','LAC','LAL','MEM','MIA','MIL','MIN','NJN','NOH','NYK','ORL','PHI','PHO','POR','SAC','SAS','SEA','TOR','UTA','WAS'],\n",
    " 2002: ['ATL','BOS','CHH','CHI','CLE','DAL','DEN','DET','GSW','HOU','IND','LAC','LAL','MEM','MIA','MIL','MIN','NJN','NYK','ORL','PHI','PHO','POR','SAC','SAS','SEA','TOR','UTA','WAS'],\n",
    " 2001: ['ATL','BOS','CHH','CHI','CLE','DAL','DEN','DET','GSW','HOU','IND','LAC','LAL','MIA','MIL','MIN','NJN','NYK','ORL','PHI','PHO','POR','SAC','SAS','SEA','TOR','UTA','VAN','WAS'],\n",
    " 2000: ['ATL','BOS','CHH','CHI','CLE','DAL','DEN','DET','GSW','HOU','IND','LAC','LAL','MIA','MIL','MIN','NJN','NYK','ORL','PHI','PHO','POR','SAC','SAS','SEA','TOR','UTA','VAN','WAS'],\n",
    " 1999: ['ATL','BOS','CHH','CHI','CLE','DAL','DEN','DET','GSW','HOU','IND','LAC','LAL','MIA','MIL','MIN','NJN','NYK','ORL','PHI','PHO','POR','SAC','SAS','SEA','TOR','UTA','VAN','WAS'],\n",
    " 1998: ['ATL','BOS','CHH','CHI','CLE','DAL','DEN','DET','GSW','HOU','IND','LAC','LAL','MIA','MIL','MIN','NJN','NYK','ORL','PHI','PHO','POR','SAC','SAS','SEA','TOR','UTA','VAN','WAS'],\n",
    " 1997: ['ATL','BOS','CHH','CHI','CLE','DAL','DEN','DET','GSW','HOU','IND','LAC','LAL','MIA','MIL','MIN','NJN','NYK','ORL','PHI','PHO','POR','SAC','SAS','SEA','TOR','UTA','VAN','WSB'],\n",
    " 1996: ['ATL','BOS','CHH','CHI','CLE','DAL','DEN','DET','GSW','HOU','IND','LAC','LAL','MIA','MIL','MIN','NJN','NYK','ORL','PHI','PHO','POR','SAC','SAS','SEA','TOR','UTA','VAN','WSB'],\n",
    " 1995: ['ATL','BOS','CHH','CHI','CLE','DAL','DEN','DET','GSW','HOU','IND','LAC','LAL','MIA','MIL','MIN','NJN','NYK','ORL','PHI','PHO','POR','SAC','SAS','SEA','UTA','WSB'],\n",
    " 1994: ['ATL','BOS','CHH','CHI','CLE','DAL','DEN','DET','GSW','HOU','IND','LAC','LAL','MIA','MIL','MIN','NJN','NYK','ORL','PHI','PHO','POR','SAC','SAS','SEA','UTA','WSB']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = '/Users/gregyannett/Documents/nba_game_models/data/gamelogs/'\n",
    "\n",
    "for year in range(1994,2022):\n",
    "    os.mkdir(working_dir+'{year}'.format(year=year))\n",
    "    for team in team_abbreviations[year]: \n",
    "        fpath = working_dir + '{year}/{team}_{year}.csv'.format(team=team, year=year)\n",
    "        get_gamelog(team, year).to_csv(fpath, index=False)\n",
    "    print(year,'done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
